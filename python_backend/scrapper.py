# -*- coding: utf-8 -*-
"""SCRAPPER.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k2hYTExrCqxJXaUfmNpHNxy__ha_WG_3
"""

#!pip install -U g4f[all]
#!pip install youtube-transcript-api nltk

from g4f.client import Client
import json
import re
import nltk
from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound
from nltk.tokenize import sent_tokenize
from nltk.probability import FreqDist
from heapq import nlargest
from googlesearch import search
import requests
from bs4 import BeautifulSoup

client = Client()
def GPT(prompt):
    response = client.chat.completions.create(
      model="gpt-4",
      messages=[{"role": "user", "content": prompt}],

    )
    return response.choices[0].message.content

def get_top_urls(query, num_results=3):
    return [url for url in search(query, stop=num_results, pause=2)]



def scrape_prompt(text_content):
    prompt_template = (
      '''You are an interactive learning assistant that structures scraped educational content into an engaging and digestible lesson format. Given the raw scraped data "{text_content}", extract the essential points and present them in a structured manner, including:

      Lesson Title: A concise and informative title based on the content

      Learning Objectives: Clearly outline what the user will gain from this lesson

      Key Concepts: Break down the information into sections with brief explanations

      Interactive Elements: Include questions, examples, or scenarios where relevant

      Summary: Provide a concise recap of the key points

      Next Steps: Suggest further reading or related lessons for deeper understanding

      Make sure the tone is informative yet engaging, using clear explanations while maintaining a logical flow. Format the response in a structured, user-friendly way suitable for an app-based learning experience.'''
)
    return prompt_template.format(text_content=text_content)




def scrape_text(url):
    headers = {"User-Agent": "Mozilla/5.0"}  # Mimic a real browser request
    response = requests.get(url, headers=headers)

    if response.status_code == 200:  # Ensure the page was successfully accessed
        soup = BeautifulSoup(response.text, "html.parser")

        # Extract all paragraph text
        paragraphs = soup.find_all("p")
        text_content = "\n".join([p.get_text() for p in paragraphs if p.get_text().strip()])
        generated_prompt=scrape_prompt(text_content)
        scrape_text=GPT(generated_prompt)
        return scrape_text

    else:
        return f"Failed to retrieve content (Status Code: {response.status_code})"
    